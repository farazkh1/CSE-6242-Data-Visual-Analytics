{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sc65O68oPNN"
      },
      "source": [
        "# DVA HW4 Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63EwvRRwocM9"
      },
      "source": [
        "Do not distribute or publish this code\n",
        "\n",
        "Do not change the **#export** statements or add and other code or comments above them. They are needed for grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uD5u3XBgn_zs"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "'''\n",
        "*** Imports ***\n",
        "    DO NOT EDIT or add anything to this section\n",
        "'''\n",
        "import csv\n",
        "import numpy as np  # http://www.numpy.org\n",
        "import ast\n",
        "from datetime import datetime\n",
        "from math import log, floor, ceil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMF-xgsFpB67"
      },
      "source": [
        "## Update 'Utility' class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlOKaA7n_zt"
      },
      "source": [
        "Modify the Utility class's methods. You can also add additional methods as required but don't change existing methods' arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAfcIKlAn_zt"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Utility(object):\n",
        "\n",
        "    def entropy(self, class_y):\n",
        "        entropy = 0\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        if len(class_y) == 0:\n",
        "            return 0\n",
        "        # Convert labels to integers to handle strings \"0\" or \"1\"\n",
        "        class_y = [int(x) for x in class_y]\n",
        "        num_ones = sum(class_y)\n",
        "        num_zeros = len(class_y) - num_ones\n",
        "        if num_ones == 0 or num_zeros == 0:\n",
        "            return 0\n",
        "        p1 = num_ones / len(class_y)\n",
        "        p0 = num_zeros / len(class_y)\n",
        "        entropy = -p1 * log(p1, 2) - p0 * log(p0, 2)\n",
        "        #############################################\n",
        "        return entropy\n",
        "\n",
        "    def partition_classes(self, X, y, split_attribute, split_val):\n",
        "        X_left = []\n",
        "        X_right = []\n",
        "        y_left = []\n",
        "        y_right = []\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        for i in range(len(X)):\n",
        "            if X[i][split_attribute] <= split_val:\n",
        "                X_left.append(X[i])\n",
        "                y_left.append(y[i])\n",
        "            else:\n",
        "                X_right.append(X[i])\n",
        "                y_right.append(y[i])\n",
        "        #############################################\n",
        "        return (X_left, X_right, y_left, y_right)\n",
        "\n",
        "    def information_gain(self, previous_y, current_y):\n",
        "        info_gain = 0\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        prev_entropy = self.entropy(previous_y)\n",
        "        left_entropy = self.entropy(current_y[0])\n",
        "        right_entropy = self.entropy(current_y[1])\n",
        "        left_weight = len(current_y[0]) / len(previous_y)\n",
        "        right_weight = len(current_y[1]) / len(previous_y)\n",
        "        info_gain = prev_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
        "        #############################################\n",
        "        return info_gain\n",
        "\n",
        "    def best_split(self, X, y):\n",
        "        split_attribute = 0\n",
        "        split_val = 0\n",
        "        X_left, X_right, y_left, y_right = [], [], [], []\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        max_info_gain = -float('inf')\n",
        "        num_features = int(len(X[0]) ** 0.5)  # Random subset of features\n",
        "        feature_indices = random.sample(range(len(X[0])), num_features)\n",
        "        \n",
        "        for attr in feature_indices:\n",
        "            values = sorted(set([row[attr] for row in X]))\n",
        "            if len(values) < 2:  # Skip if not enough distinct values\n",
        "                continue\n",
        "            split_candidates = [(values[i] + values[i+1]) / 2 for i in range(len(values)-1)]\n",
        "            \n",
        "            for val in split_candidates:\n",
        "                X_l, X_r, y_l, y_r = self.partition_classes(X, y, attr, val)\n",
        "                if len(y_l) == 0 or len(y_r) == 0:\n",
        "                    continue\n",
        "                curr_y = [y_l, y_r]\n",
        "                gain = self.information_gain(y, curr_y)\n",
        "                if gain > max_info_gain:\n",
        "                    max_info_gain = gain\n",
        "                    split_attribute = attr\n",
        "                    split_val = val\n",
        "                    X_left, X_right, y_left, y_right = X_l, X_r, y_l, y_r\n",
        "        \n",
        "        if max_info_gain <= 0:  # No valid split found\n",
        "            return {\n",
        "                'split_attribute': 0,\n",
        "                'split_val': 0,\n",
        "                'X_left': [],\n",
        "                'X_right': [],\n",
        "                'y_left': [],\n",
        "                'y_right': [],\n",
        "                'info_gain': 0\n",
        "            }\n",
        "        \n",
        "        return {\n",
        "            'split_attribute': split_attribute,\n",
        "            'split_val': split_val,\n",
        "            'X_left': X_left,\n",
        "            'X_right': X_right,\n",
        "            'y_left': y_left,\n",
        "            'y_right': y_right,\n",
        "            'info_gain': max_info_gain\n",
        "        }\n",
        "        #############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xITJYXln_zu"
      },
      "source": [
        "## Update the 'DecisionTree' and 'RandomForest' classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZkW-Qk7n_zu"
      },
      "source": [
        "Please modify the 'DecisionTree' and 'RandomForest' classes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEheMuC3n_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class DecisionTree(object):\n",
        "    def __init__(self, max_depth):\n",
        "        self.tree = {}\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def learn(self, X, y, par_node = {}, depth=0):\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        # Stop if pure, max depth reached, or too few samples\n",
        "        y_int = [int(label) for label in y]  # Convert for set comparison\n",
        "        if len(set(y_int)) == 1 or depth >= self.max_depth or len(X) < 2:\n",
        "            majority = max(set(y), key=y.count)  # Keep original type\n",
        "            self.tree = {'leaf': True, 'class': majority}\n",
        "            return\n",
        "        \n",
        "        util = Utility()\n",
        "        split_info = util.best_split(X, y)\n",
        "        \n",
        "        if split_info['info_gain'] <= 0 or not split_info['X_left']:\n",
        "            majority = max(set(y), key=y.count)\n",
        "            self.tree = {'leaf': True, 'class': majority}\n",
        "            return\n",
        "        \n",
        "        self.tree = {\n",
        "            'leaf': False,\n",
        "            'split_attribute': split_info['split_attribute'],\n",
        "            'split_val': split_info['split_val'],\n",
        "            'left': DecisionTree(self.max_depth),\n",
        "            'right': DecisionTree(self.max_depth)\n",
        "        }\n",
        "        \n",
        "        self.tree['left'].learn(split_info['X_left'], split_info['y_left'], depth=depth+1)\n",
        "        self.tree['right'].learn(split_info['X_right'], split_info['y_right'], depth=depth+1)\n",
        "        #############################################\n",
        "\n",
        "    def classify(self, record):\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        node = self.tree\n",
        "        while not node['leaf']:\n",
        "            attr = node['split_attribute']\n",
        "            val = node['split_val']\n",
        "            if record[attr] <= val:\n",
        "                node = node['left'].tree\n",
        "            else:\n",
        "                node = node['right'].tree\n",
        "        return node['class']  # Return original type from training\n",
        "        #############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnmeoxynn_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class RandomForest(object):\n",
        "    num_trees = 0\n",
        "    decision_trees = []\n",
        "    bootstraps_datasets = []\n",
        "    bootstraps_labels = []\n",
        "\n",
        "    def __init__(self, num_trees):\n",
        "        self.num_trees = num_trees\n",
        "        self.decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n",
        "        self.bootstraps_datasets = []\n",
        "        self.bootstraps_labels = []\n",
        "\n",
        "    def _bootstrapping(self, XX, n):\n",
        "        sample = []\n",
        "        labels = []\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        indices = [random.randint(0, n-1) for _ in range(n)]\n",
        "        for idx in indices:\n",
        "            sample.append(XX[idx][:-1])\n",
        "            labels.append(XX[idx][-1])  # Preserve original label type\n",
        "        #############################################\n",
        "        return (sample, labels)\n",
        "\n",
        "    def bootstrapping(self, XX):\n",
        "        for i in range(self.num_trees):\n",
        "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
        "            self.bootstraps_datasets.append(data_sample)\n",
        "            self.bootstraps_labels.append(data_label)\n",
        "\n",
        "    def fitting(self):\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        for i in range(self.num_trees):\n",
        "            self.decision_trees[i].learn(self.bootstraps_datasets[i], self.bootstraps_labels[i])\n",
        "        #############################################\n",
        "\n",
        "    def voting(self, X):\n",
        "        y = []\n",
        "        for record in X:\n",
        "            votes = []\n",
        "            for i in range(len(self.bootstraps_datasets)):\n",
        "                dataset = self.bootstraps_datasets[i]\n",
        "                if record not in dataset:\n",
        "                    OOB_tree = self.decision_trees[i]\n",
        "                    vote = OOB_tree.classify(record)\n",
        "                    votes.append(vote)\n",
        "            if len(votes) == 0:\n",
        "                ### Implement your code here\n",
        "                #############################################\n",
        "                all_votes = [tree.classify(record) for tree in self.decision_trees]\n",
        "                majority_vote = max(set(all_votes), key=all_votes.count)\n",
        "                y.append(majority_vote)\n",
        "                #############################################\n",
        "            else:\n",
        "                counts = {}\n",
        "                for vote in votes:\n",
        "                    counts[vote] = counts.get(vote, 0) + 1\n",
        "                majority_vote = max(counts, key=counts.get)\n",
        "                y.append(majority_vote)\n",
        "        return np.array(y)\n",
        "\n",
        "    def user(self):\n",
        "        ### Implement your code here\n",
        "        #############################################\n",
        "        return 'your GT ID' \n",
        "        #############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpMChIARn_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "\n",
        "# TODO: Determine the forest size according to your implementation.\n",
        "# This function will be used by the autograder to set your forest size during testing\n",
        "# VERY IMPORTANT: Minimum forest_size should be 10\n",
        "def get_forest_size():\n",
        "    forest_size = 25\n",
        "    return forest_size\n",
        "\n",
        "# TODO: Determine random seed to set for reproducibility\n",
        "# This function will be used by the autograder to set the random seed to obtain the same results you achieve locally\n",
        "def get_random_seed():\n",
        "    random_seed = 42\n",
        "    return random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLEiqrKn_zu"
      },
      "source": [
        "## Do not modify the below cell\n",
        "The cell below is provided to test that your random forest classifier can be successfully built and run. Similar steps will be used to build and run your code in Gradescope. Any additional testing of functions can be done in the cells below the `run()` cell, as these will not be parsed by the autograder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VxPPVN8dn_zu"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "    np.random.seed(get_random_seed())\n",
        "    # start time\n",
        "    start = datetime.now()\n",
        "    X = list()\n",
        "    y = list()\n",
        "    XX = list()  # Contains data features and data labels\n",
        "    numerical_cols = set([i for i in range(0, 31)])  # indices of numeric attributes (columns)\n",
        "\n",
        "    # Loading data set\n",
        "    print(\"reading the data\")\n",
        "    with open(\"Wisconsin_breast_prognostic.csv\") as f:\n",
        "        next(f, None)\n",
        "        for line in csv.reader(f, delimiter=\",\"):\n",
        "            xline = []\n",
        "            for i in range(len(line)):\n",
        "                if i in numerical_cols:\n",
        "                    xline.append(ast.literal_eval(line[i]))\n",
        "                else:\n",
        "                    xline.append(line[i])\n",
        "\n",
        "            X.append(xline[:-1])\n",
        "            y.append(xline[-1])\n",
        "            XX.append(xline[:])\n",
        "\n",
        "    # Initializing a random forest.\n",
        "    randomForest = RandomForest(get_forest_size())\n",
        "\n",
        "    # printing the name\n",
        "    print(\"__Name: \" + randomForest.user()+\"__\")\n",
        "\n",
        "    # Creating the bootstrapping datasets\n",
        "    print(\"creating the bootstrap datasets\")\n",
        "    randomForest.bootstrapping(XX)\n",
        "\n",
        "    # Building trees in the forest\n",
        "    print(\"fitting the forest\")\n",
        "    randomForest.fitting()\n",
        "\n",
        "    # Calculating an unbiased error estimation of the random forest\n",
        "    # based on out-of-bag (OOB) error estimate.\n",
        "    y_predicted = randomForest.voting(X)\n",
        "\n",
        "    # Comparing predicted and true labels\n",
        "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = float(results.count(True)) / float(len(results))\n",
        "\n",
        "    print(\"accuracy: %.4f\" % accuracy)\n",
        "    print(\"OOB estimate: %.4f\" % (1 - accuracy))\n",
        "\n",
        "    # end time\n",
        "    print(\"Execution time: \" + str(datetime.now() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IaK7xdjNn_zv"
      },
      "outputs": [],
      "source": [
        "# Call the run() function to test your implementation\n",
        "# Use this cell and any cells below for additional testing\n",
        "run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 ('py3.7')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "bf1e8345f3991e63f0377349612043dc62e53d2db35e0306b2f24fb858f18319"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
